{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Project Documentation","text":""},{"location":"#main_1","title":"<code>main</code>","text":""},{"location":"#main.main","title":"<code>main(mode, train_sample_size='medium', eval_sample_size='medium', export_to_onnx=False, export_to_bento=False)</code>","text":"<p>Main function to handle training or evaluation of the model.</p> <pre><code>Args:\n    mode:  Specifies whether to 'train' or 'eval'uate the model.\n    train_sample_size: The size of the training dataset (\"small\", \"medium\", or \"large\"). Defaults to \"medium\".\n    eval_sample_size: The size of the evaluation dataset (\"small\", \"medium\", or \"large\"). Defaults to \"medium\".\n    export_to_onnx:  A boolean indicating whether to export the model to ONNX format. Defaults to False.\n    export_to_bento: A boolean indicating whether to export the model to BentoML format. Defaults to False.\n\nReturns:\n    None\n</code></pre> Source code in <code>itmo_mlops_course\\main.py</code> <pre><code>def main(\n    mode: str,\n    train_sample_size: str = \"medium\",\n    eval_sample_size: str = \"medium\",\n    export_to_onnx: bool = False,\n    export_to_bento: bool = False,\n) -&gt; None:\n    \"\"\"\n    Main function to handle training or evaluation of the model.\n\n        Args:\n            mode:  Specifies whether to 'train' or 'eval'uate the model.\n            train_sample_size: The size of the training dataset (\"small\", \"medium\", or \"large\"). Defaults to \"medium\".\n            eval_sample_size: The size of the evaluation dataset (\"small\", \"medium\", or \"large\"). Defaults to \"medium\".\n            export_to_onnx:  A boolean indicating whether to export the model to ONNX format. Defaults to False.\n            export_to_bento: A boolean indicating whether to export the model to BentoML format. Defaults to False.\n\n        Returns:\n            None\n    \"\"\"\n\n    if mode == \"train\":\n\n        # Clearml task initiation\n        task = Task.init(\n            project_name=\"itmo_mlops_2024\",\n            task_name=\"training\",\n            task_type=Task.TaskTypes.training,\n            tags=[\"fasterrcnn_resnet50_fpn\", \"detection\"],\n        )\n\n        dataframe = get_processed_annotations(\n            images_set=f\"src/prepared_samples/train_{train_sample_size}.txt\",\n            xml_path=\"src/annotations\",\n        )\n\n        # uploading training set to Clearml\n        task.upload_artifact(\n            name=f\"training sample: size -&gt; {train_sample_size}\",\n            artifact_object=dataframe,\n        )\n\n        torch_dataset = AirfieldDataset(\n            dataframe=dataframe,\n            paths=get_image_paths(\"src/prepared_samples/train_medium.txt\"),\n        )\n\n        # configuring the experiment\n        experiment = Experiment(\n            dataset=torch_dataset,\n            model=model,\n            optimizer=optimizer,\n            lr_scheduler=lr_scheduler,\n            logger=task.get_logger(),\n            config={\n                \"model_name\": \"fasterrcnn_resnet50_fpn\",\n                \"optim_name\": \"sgd\",\n                \"checkpoint_path\": \"models_history/models_torch\",\n                \"train_loader_batch\": 8,\n                \"eval_loader_batch\": 4,\n                \"num_epochs\": 5,\n                \"mode\": \"train\",\n            },\n        )\n\n        # experiment.execute()\n        if export_to_onnx:\n            experiment.export_to_onnx(model_name=\"faster_rcnn_tuned_v3\")\n\n        if export_to_bento:\n            experiment.export_to_bento(\n                bento_name=\"aircraft_detection_faster_rcnn\",\n                tags={\"stage\": \"dev\", \"team\": \"cv\"},\n            )\n\n        task.close()\n\n    if mode == \"eval\":\n\n        # Clearml task initiation\n        task = Task.init(\n            project_name=\"itmo_mlops_2024\",\n            task_name=\"evaluation\",\n            task_type=Task.TaskTypes.inference,\n            tags=[\"fasterrcnn_resnet50_fpn\", \"detection\"],\n        )\n\n        dataframe = get_processed_annotations(\n            images_set=f\"src/prepared_samples/test_{eval_sample_size}.txt\",\n            xml_path=\"src/annotations\",\n        )\n\n        # uploading evaluation set to Clearml\n        task.upload_artifact(\n            name=f\"eval sample: size -&gt; {eval_sample_size}\", artifact_object=dataframe\n        )\n\n        torch_dataset = AirfieldDataset(\n            dataframe=dataframe,\n            paths=get_image_paths(\"src/prepared_samples/test_medium.txt\"),\n        )\n\n        # configuring the experiment\n        experiment = Experiment(\n            dataset=torch_dataset,\n            model=model,\n            optimizer=optimizer,\n            lr_scheduler=lr_scheduler,\n            logger=task.get_logger(),\n            config={\n                \"model_name\": \"fasterrcnn_resnet50_fpn\",\n                \"optim_name\": \"sgd\",\n                \"eval_loader_batch\": 4,\n                \"mode\": \"eval\",\n            },\n        )\n\n        # getting the predictions\n        predictions = experiment.execute()\n\n        # uploading predictions df to Clearml\n        task.upload_artifact(name=f\"predictions dataframe\", artifact_object=predictions)\n        task.close()\n</code></pre>"},{"location":"#bentoservice","title":"<code>bento.service</code>","text":""},{"location":"#bento.service.SpyAircraftDetector","title":"<code>SpyAircraftDetector</code>","text":"<p>Detects spy aircraft in images using a BentoML model.</p> Source code in <code>itmo_mlops_course\\bento\\service.py</code> <pre><code>@bentoml.service(\n    resources={\"cpu\": \"2\"},\n    traffic={\"timeout\": 10},\n)\nclass SpyAircraftDetector:\n    \"\"\"\n    Detects spy aircraft in images using a BentoML model.\"\"\"\n\n    # loading the fine-tuned model\n    bento_model = bentoml.models.get(\"aircraft_detection_faster_rcnn:latest\")\n\n    def __init__(self):\n        \"\"\"\n        Initializes the model with device, loads the BentoML model, and sets up image transforms.\n\n            Args:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        self.device = (\n            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n        )\n        self.model = bentoml.pytorch.load_model(self.bento_model)\n\n        # image transforms list\n        self.processor = v2.Compose(\n            [\n                v2.Resize((800, 800)),\n                v2.ToImage(),\n                v2.ToDtype(torch.float32, scale=True),\n                v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n            ]\n        )\n\n    @bentoml.api\n    async def predict(self, img: Image) -&gt; Image:\n        \"\"\"predicts bounding boxes for given image\"\"\"\n\n        # switching model to evaluation mode\n        self.model.to(self.device)\n        self.model.eval()\n\n        # preparing image to draw predicted bounding boxes\n        img = img.resize(size=(800, 800))\n        draw = Draw(img)\n\n        # image processing, torch.unsqueeze are required for avoid error caused by tensor dimensions\n        processed_img = self.processor(img.convert(mode=\"RGB\"))\n        processed_img = list(torch.unsqueeze(processed_img, dim=0).to(self.device))\n\n        # getting the predictions\n        outputs = self.model(processed_img)\n\n        # access to predicted bounding boxes and their scores\n        predictions = outputs[0][\"boxes\"].data.cpu().numpy()\n        scores = outputs[0][\"scores\"].data.cpu().numpy()\n\n        predictions = predictions[scores &gt;= 0.5].astype(np.int32)\n        scores = scores[scores &gt;= 0.5]\n        print(predictions, scores)\n\n        # draw each bounding box and it's score in our predictions\n        for box, score in zip(predictions, scores):\n\n            box = tuple(map(int, box))\n\n            draw.rectangle(xy=box, outline=\"blue\", width=2)\n            draw.text(\n                xy=(box[0], box[1]),\n                text=f\"box score: {round(float(score), 4)}\",\n                stroke_width=0.35,\n                fill=\"black\",\n            )\n\n        return img\n</code></pre>"},{"location":"#bento.service.SpyAircraftDetector.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the model with device, loads the BentoML model, and sets up image transforms.</p> <pre><code>Args:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>itmo_mlops_course\\bento\\service.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the model with device, loads the BentoML model, and sets up image transforms.\n\n        Args:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    self.device = (\n        torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    )\n    self.model = bentoml.pytorch.load_model(self.bento_model)\n\n    # image transforms list\n    self.processor = v2.Compose(\n        [\n            v2.Resize((800, 800)),\n            v2.ToImage(),\n            v2.ToDtype(torch.float32, scale=True),\n            v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ]\n    )\n</code></pre>"},{"location":"#bento.service.SpyAircraftDetector.predict","title":"<code>predict(img)</code>  <code>async</code>","text":"<p>predicts bounding boxes for given image</p> Source code in <code>itmo_mlops_course\\bento\\service.py</code> <pre><code>@bentoml.api\nasync def predict(self, img: Image) -&gt; Image:\n    \"\"\"predicts bounding boxes for given image\"\"\"\n\n    # switching model to evaluation mode\n    self.model.to(self.device)\n    self.model.eval()\n\n    # preparing image to draw predicted bounding boxes\n    img = img.resize(size=(800, 800))\n    draw = Draw(img)\n\n    # image processing, torch.unsqueeze are required for avoid error caused by tensor dimensions\n    processed_img = self.processor(img.convert(mode=\"RGB\"))\n    processed_img = list(torch.unsqueeze(processed_img, dim=0).to(self.device))\n\n    # getting the predictions\n    outputs = self.model(processed_img)\n\n    # access to predicted bounding boxes and their scores\n    predictions = outputs[0][\"boxes\"].data.cpu().numpy()\n    scores = outputs[0][\"scores\"].data.cpu().numpy()\n\n    predictions = predictions[scores &gt;= 0.5].astype(np.int32)\n    scores = scores[scores &gt;= 0.5]\n    print(predictions, scores)\n\n    # draw each bounding box and it's score in our predictions\n    for box, score in zip(predictions, scores):\n\n        box = tuple(map(int, box))\n\n        draw.rectangle(xy=box, outline=\"blue\", width=2)\n        draw.text(\n            xy=(box[0], box[1]),\n            text=f\"box score: {round(float(score), 4)}\",\n            stroke_width=0.35,\n            fill=\"black\",\n        )\n\n    return img\n</code></pre>"},{"location":"#corecustom_datasets","title":"<code>core.custom_datasets</code>","text":""},{"location":"#core.custom_datasets.AirfieldDataset","title":"<code>AirfieldDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>itmo_mlops_course\\core\\custom_datasets.py</code> <pre><code>class AirfieldDataset(Dataset):\n\n    def __init__(\n        self,\n        dataframe: pd.DataFrame,\n        paths: list,\n        transforms: torchvision.transforms.Compose = None,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the dataset.\n\n            Args:\n                dataframe: A pandas DataFrame containing image IDs.\n                paths: A list of paths to the images.\n                transforms: An optional torchvision transforms Compose object for data augmentation and preprocessing.\n                    If None, default transformations are applied (resize, convert to PIL Image, normalize).\n\n            Returns:\n                None\n        \"\"\"\n        super().__init__()\n\n        self.image_ids = dataframe[\"image_id\"].unique()\n        self.df = dataframe\n        self.paths = paths\n\n        if transforms is None:\n            self.transforms = v2.Compose(\n                [\n                    v2.Resize((800, 800)),\n                    v2.ToImage(),\n                    v2.ToDtype(torch.float32, scale=True),\n                    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n                ]\n            )\n        else:\n            self.transforms = transforms\n\n    \"\"\"\n        Custom dataset for custom object detection task,\n        \"aircraft identification on the airfield\"\n    \"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of images in the dataset.\n\n          Args:\n            None\n\n          Returns:\n            int: The number of image IDs stored in the dataset.\n        \"\"\"\n        return self.image_ids.shape[0]\n\n    def __getitem__(self, index: int):\n        \"\"\"\n        Retrieves an image and its corresponding targets from the dataset.\n\n            Args:\n                index: The index of the item to retrieve.\n\n            Returns:\n                tuple: A tuple containing the image tensor, a dictionary of target tensors\n                       (boxes, labels, image_id, roi), and the image ID.\n        \"\"\"\n\n        image_id = self.image_ids[index]\n\n        image = Image.open(f\"{self.paths[index]}\")\n        image = self.transforms(image)\n\n        records = self.df[self.df[\"image_id\"] == image_id]\n\n        # converting bboxes into tensor\n        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n\n        roi = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        roi = torch.as_tensor(roi, dtype=torch.float32)\n\n        # if needed it labels might be different\n        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n\n        targets = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"image_id\": torch.tensor([index]),\n            \"roi\": roi,\n        }\n\n        return image, targets, image_id\n</code></pre>"},{"location":"#core.custom_datasets.AirfieldDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Retrieves an image and its corresponding targets from the dataset.</p> <pre><code>Args:\n    index: The index of the item to retrieve.\n\nReturns:\n    tuple: A tuple containing the image tensor, a dictionary of target tensors\n           (boxes, labels, image_id, roi), and the image ID.\n</code></pre> Source code in <code>itmo_mlops_course\\core\\custom_datasets.py</code> <pre><code>def __getitem__(self, index: int):\n    \"\"\"\n    Retrieves an image and its corresponding targets from the dataset.\n\n        Args:\n            index: The index of the item to retrieve.\n\n        Returns:\n            tuple: A tuple containing the image tensor, a dictionary of target tensors\n                   (boxes, labels, image_id, roi), and the image ID.\n    \"\"\"\n\n    image_id = self.image_ids[index]\n\n    image = Image.open(f\"{self.paths[index]}\")\n    image = self.transforms(image)\n\n    records = self.df[self.df[\"image_id\"] == image_id]\n\n    # converting bboxes into tensor\n    boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n\n    roi = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n    roi = torch.as_tensor(roi, dtype=torch.float32)\n\n    # if needed it labels might be different\n    labels = torch.ones((records.shape[0],), dtype=torch.int64)\n\n    targets = {\n        \"boxes\": boxes,\n        \"labels\": labels,\n        \"image_id\": torch.tensor([index]),\n        \"roi\": roi,\n    }\n\n    return image, targets, image_id\n</code></pre>"},{"location":"#core.custom_datasets.AirfieldDataset.__init__","title":"<code>__init__(dataframe, paths, transforms=None)</code>","text":"<p>Initializes the dataset.</p> <pre><code>Args:\n    dataframe: A pandas DataFrame containing image IDs.\n    paths: A list of paths to the images.\n    transforms: An optional torchvision transforms Compose object for data augmentation and preprocessing.\n        If None, default transformations are applied (resize, convert to PIL Image, normalize).\n\nReturns:\n    None\n</code></pre> Source code in <code>itmo_mlops_course\\core\\custom_datasets.py</code> <pre><code>def __init__(\n    self,\n    dataframe: pd.DataFrame,\n    paths: list,\n    transforms: torchvision.transforms.Compose = None,\n) -&gt; None:\n    \"\"\"\n    Initializes the dataset.\n\n        Args:\n            dataframe: A pandas DataFrame containing image IDs.\n            paths: A list of paths to the images.\n            transforms: An optional torchvision transforms Compose object for data augmentation and preprocessing.\n                If None, default transformations are applied (resize, convert to PIL Image, normalize).\n\n        Returns:\n            None\n    \"\"\"\n    super().__init__()\n\n    self.image_ids = dataframe[\"image_id\"].unique()\n    self.df = dataframe\n    self.paths = paths\n\n    if transforms is None:\n        self.transforms = v2.Compose(\n            [\n                v2.Resize((800, 800)),\n                v2.ToImage(),\n                v2.ToDtype(torch.float32, scale=True),\n                v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n            ]\n        )\n    else:\n        self.transforms = transforms\n</code></pre>"},{"location":"#core.custom_datasets.AirfieldDataset.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of images in the dataset.</p> <p>Args:     None</p> <p>Returns:     int: The number of image IDs stored in the dataset.</p> Source code in <code>itmo_mlops_course\\core\\custom_datasets.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of images in the dataset.\n\n      Args:\n        None\n\n      Returns:\n        int: The number of image IDs stored in the dataset.\n    \"\"\"\n    return self.image_ids.shape[0]\n</code></pre>"},{"location":"#coreexperiment","title":"<code>core.experiment</code>","text":""},{"location":"#core.experiment.Experiment","title":"<code>Experiment</code>","text":"Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>class Experiment:\n\n    def __init__(\n        self,\n        dataset: torch.utils.data.Dataset,\n        model: torch.nn.Module,\n        optimizer: torch.optim.Optimizer,\n        lr_scheduler: torch.optim.lr_scheduler,\n        logger: Logger,\n        config: dict,\n    ) -&gt; None:\n        \"\"\"\n        Initializes the Trainer with training components.\n\n            Args:\n                dataset: The dataset to be used for training.\n                model: The neural network model to train.\n                optimizer: The optimizer used for updating model parameters.\n                lr_scheduler: The learning rate scheduler.\n                logger: A logger object for tracking training progress.\n                config: A dictionary containing configuration parameters.\n\n            Returns:\n                None\n        \"\"\"\n        self.dataset = dataset\n        self.model = model\n        self.optimizer = optimizer\n        self.lr_scheduler = lr_scheduler\n        self.logger = logger\n        self.collate_fn = collate_fn\n        self.device = (\n            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n        )\n        self.config = config\n\n    \"\"\"\n        Class that builds our experiment with neural network.\n        Just specify parameters of experiment such as optimizer,\n        device, ml/dl model, etc. \n    \"\"\"\n\n    def train(self, dataloader: DataLoader) -&gt; None:\n        \"\"\"\n        Implements network training process\n        :param dataloader: PyTorch standard DataLoader which contains custom dataset\n        \"\"\"\n\n        # setting some counters and such things\n        itr = 1\n        start_time = time()\n        model_name, optim_name, checkpoint_path, num_epochs = (\n            self.get_constants_from_config()\n        )\n\n        # switching model into train mode\n        self.model.to(self.device)\n        self.model.train()\n\n        # losses history\n        loss_hist = Averager()\n\n        self.logger.report_text(\"Training process is started!\")\n\n        try:\n\n            # training loop\n            for epoch in range(num_epochs):\n\n                loss_hist.reset()\n\n                for images, targets, image_ids in dataloader:\n\n                    images = list(image.to(self.device) for image in images)\n\n                    targets = [\n                        {k: v.to(self.device) for k, v in t.items()} for t in targets\n                    ]\n\n                    # forward pass\n                    loss_dict = self.model(images, targets)\n\n                    # compute and send average batch loss\n                    losses = sum(loss for loss in loss_dict.values())\n                    loss_value = losses.item()\n\n                    loss_hist.send(loss_value)\n\n                    # backward pass\n                    self.optimizer.zero_grad()\n                    losses.backward()\n                    self.optimizer.step()\n\n                    # logging loss\n                    self.logger.report_scalar(\n                        title=\"training loss\",\n                        series=\"avg batch loss\",\n                        iteration=itr,\n                        value=loss_hist.value,\n                    )\n\n                    # logging image samples from training set\n                    [\n                        self.logger.report_image(\n                            title=\"image\",\n                            series=f\"Batch of images on itr: {itr}\",\n                            iteration=itr,\n                            image=Image.open(f\"src/data/{img}.jpg\"),\n                        )\n                        for img in image_ids\n                    ]\n\n                    self.logger.report_text(f\"Iteration: {itr}\")\n                    itr += 1\n\n                # logging learning rate\n                self.logger.report_scalar(\n                    title=\"learning rate\",\n                    series=\"lr\",\n                    iteration=itr,\n                    value=self.lr_scheduler.get_last_lr()[0],\n                )\n\n                # learning rate update after each train epoch\n                self.lr_scheduler.step()\n\n                self.logger.report_text(f\"Train Epoch: {epoch}, Iteration: {itr}\")\n\n        # checkpoint for unplanned or manual training interruption\n        except Union[KeyboardInterrupt, TypeError, Exception]:\n\n            torch.save(\n                self.model.state_dict(), f=f\"{checkpoint_path}/{model_name}_{itr}.pth\"\n            )\n\n            self.logger.report_text(\n                \"Process are finished manually! Model saved into checkpoint\"\n            )\n\n        # model saving after successfully train\n        torch.save(\n            self.model.state_dict(),\n            f=f\"{checkpoint_path}/{model_name}_{optim_name}_tuned.pth\",\n        )\n\n        # logging training time\n        end_time = time()\n        self.logger.report_text(\n            f\"Execution time: {(end_time - start_time) / 60} minutes\"\n        )\n\n    def get_predictions_dataset(\n        self, dataloader: DataLoader, threshold: float = 0.5\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Implements network performance evaluation process\n        :param dataloader: PyTorch standard DataLoader which contains custom dataset\n        :param threshold: filtering bound for predicted samples\n        \"\"\"\n        predictions = {\"image_id\": [], \"boxes\": [], \"IoU\": []}\n\n        # switching model into evaluation mode\n        self.model.to(self.device)\n        self.model.eval()\n\n        itr = 1\n\n        # evaluation loop\n        for images, targets, image_ids in dataloader:\n\n            images = list(image.to(self.device) for image in images)\n\n            # get predictions of the model\n            outputs = self.model(images)\n\n            for i, image in enumerate(images):\n\n                ground_truth = targets[i][\"boxes\"]\n                output_boxes = outputs[i][\"boxes\"].data.cpu().numpy()\n\n                scores = outputs[i][\"scores\"].data.cpu().numpy()\n\n                output_boxes = output_boxes[scores &gt;= threshold].astype(np.int32)\n\n                image_id = image_ids[i]\n\n                # Pillow class for drawing predicted bounding boxes\n                draw = ImageDraw.Draw(Image.open(f\"src/data/{image_id}.jpg\"))\n\n                # storing the iou's for each predicted object\n                pred_objects_iou = []\n\n                for box in output_boxes:\n\n                    # iou computation for each predicted bbox\n                    # torchvision.ops.box_iou returns Tensor after call\n                    tensor_iou = box_iou(\n                        torch.tensor(ground_truth), torch.tensor(box.reshape(-1, 4))\n                    )\n\n                    # tensor conversion into python dtype\n                    iou = round(float(torch.max(tensor_iou)), 4)\n\n                    pred_objects_iou.append(iou)\n\n                    predictions[\"image_id\"].append(image_id)\n                    predictions[\"boxes\"].append(box)\n                    predictions[\"IoU\"].append(iou)\n\n                    draw.rectangle(xy=tuple(map(int, box)), outline=\"blue\", width=2)\n                    draw.text(\n                        xy=(box[0], box[1]),\n                        text=f\"IoU: {iou}\",\n                        fill=\"black\",\n                        stroke=0.2,\n                    )\n\n                # logging the image with predicted bounding boxes\n                self.logger.report_image(\n                    title=\"image\",\n                    series=f\"image sample: {image_id}\",\n                    iteration=itr,\n                    image=draw._image,\n                )\n\n                # scoring avg iou for image and logging it\n                self.logger.report_scalar(\n                    title=\"avg IoU (Jaccard index)\",\n                    series=f\"avg IoU\",\n                    iteration=itr,\n                    value=sum(pred_objects_iou)\n                    / (len(output_boxes) if len(output_boxes) &gt; 0 else 1),\n                )\n\n                itr += 1\n\n        return pd.DataFrame.from_dict(predictions)\n\n    def execute(self) -&gt; Union[pd.DataFrame, None]:\n        \"\"\"\n        Method for triggering pipeline execution\n        \"\"\"\n        self.logger.report_text(f\"execution configuration: {self.config}\")\n\n        if self.config[\"mode\"] == \"train\":\n\n            loader = DataLoader(\n                self.dataset,\n                batch_size=self.config.get(\"train_loader_batch\", 1),\n                shuffle=False,\n                collate_fn=self.collate_fn,\n            )\n            self.train(dataloader=loader)\n\n        if self.config[\"mode\"] == \"eval\":\n\n            loader = DataLoader(\n                self.dataset,\n                batch_size=self.config.get(\"eval_loader_batch\", 1),\n                shuffle=False,\n                collate_fn=self.collate_fn,\n            )\n            return self.get_predictions_dataset(dataloader=loader)\n\n    def export_to_onnx(\n        self,\n        export_path: str = \"models_history/models_onnx\",\n        model_name: str = \"faster_rcnn_tuned\",\n    ) -&gt; None:\n        \"\"\"\n        Converting current model into ONNX format\n        :param model_name: converted model file name\n        :param export_path: destination directory for converted model\n\n        *required ONNX version: 1.16.1; pip install onnx=1.16.1\n        \"\"\"\n        model_to_export = self.model\n\n        # this operation requires switching the model into eval mode\n        model_to_export.eval()\n\n        # input template for ONNX converted network should be the same\n        input_tensor = torch.randn(\n            (4, 3, 800, 800), dtype=torch.float32, requires_grad=True\n        )\n        # input_tensor = input_tensor.to(self.device)\n\n        torch.onnx.export(\n            model_to_export,\n            (input_tensor,),\n            f\"{export_path}/{model_name}.onnx\",\n            export_params=True,\n            do_constant_folding=True,\n            opset_version=11,\n            input_names=[\"input\"],\n            output_names=[\"output\"],\n            dynamo=False,\n        )\n        self.logger.report_text(\"Model successfully exported into ONNX format\")\n\n    def export_to_bento(self, bento_name: str, tags: dict) -&gt; bentoml.Model:\n        \"\"\"Saves model into BentoML\"\"\"\n        return bentoml.pytorch.save_model(\n            name=bento_name, labels=tags, model=self.model\n        )\n\n    def get_constants_from_config(self) -&gt; tuple:\n        \"\"\"Parses given constants into tuple\"\"\"\n\n        model = self.config.get(\"model_name\", \"model\")\n        optim = self.config.get(\"optim_name\", \"\")\n        checkpoint_path = self.config.get(\n            \"checkpoint_path\", \"models_history/models_torch\"\n        )\n\n        num_epochs = self.config.get(\"num_epochs\", 5)\n\n        return model, optim, checkpoint_path, num_epochs\n</code></pre>"},{"location":"#core.experiment.Experiment.__init__","title":"<code>__init__(dataset, model, optimizer, lr_scheduler, logger, config)</code>","text":"<p>Initializes the Trainer with training components.</p> <pre><code>Args:\n    dataset: The dataset to be used for training.\n    model: The neural network model to train.\n    optimizer: The optimizer used for updating model parameters.\n    lr_scheduler: The learning rate scheduler.\n    logger: A logger object for tracking training progress.\n    config: A dictionary containing configuration parameters.\n\nReturns:\n    None\n</code></pre> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def __init__(\n    self,\n    dataset: torch.utils.data.Dataset,\n    model: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    lr_scheduler: torch.optim.lr_scheduler,\n    logger: Logger,\n    config: dict,\n) -&gt; None:\n    \"\"\"\n    Initializes the Trainer with training components.\n\n        Args:\n            dataset: The dataset to be used for training.\n            model: The neural network model to train.\n            optimizer: The optimizer used for updating model parameters.\n            lr_scheduler: The learning rate scheduler.\n            logger: A logger object for tracking training progress.\n            config: A dictionary containing configuration parameters.\n\n        Returns:\n            None\n    \"\"\"\n    self.dataset = dataset\n    self.model = model\n    self.optimizer = optimizer\n    self.lr_scheduler = lr_scheduler\n    self.logger = logger\n    self.collate_fn = collate_fn\n    self.device = (\n        torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    )\n    self.config = config\n</code></pre>"},{"location":"#core.experiment.Experiment.execute","title":"<code>execute()</code>","text":"<p>Method for triggering pipeline execution</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def execute(self) -&gt; Union[pd.DataFrame, None]:\n    \"\"\"\n    Method for triggering pipeline execution\n    \"\"\"\n    self.logger.report_text(f\"execution configuration: {self.config}\")\n\n    if self.config[\"mode\"] == \"train\":\n\n        loader = DataLoader(\n            self.dataset,\n            batch_size=self.config.get(\"train_loader_batch\", 1),\n            shuffle=False,\n            collate_fn=self.collate_fn,\n        )\n        self.train(dataloader=loader)\n\n    if self.config[\"mode\"] == \"eval\":\n\n        loader = DataLoader(\n            self.dataset,\n            batch_size=self.config.get(\"eval_loader_batch\", 1),\n            shuffle=False,\n            collate_fn=self.collate_fn,\n        )\n        return self.get_predictions_dataset(dataloader=loader)\n</code></pre>"},{"location":"#core.experiment.Experiment.export_to_bento","title":"<code>export_to_bento(bento_name, tags)</code>","text":"<p>Saves model into BentoML</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def export_to_bento(self, bento_name: str, tags: dict) -&gt; bentoml.Model:\n    \"\"\"Saves model into BentoML\"\"\"\n    return bentoml.pytorch.save_model(\n        name=bento_name, labels=tags, model=self.model\n    )\n</code></pre>"},{"location":"#core.experiment.Experiment.export_to_onnx","title":"<code>export_to_onnx(export_path='models_history/models_onnx', model_name='faster_rcnn_tuned')</code>","text":"<p>Converting current model into ONNX format :param model_name: converted model file name :param export_path: destination directory for converted model</p> <p>*required ONNX version: 1.16.1; pip install onnx=1.16.1</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def export_to_onnx(\n    self,\n    export_path: str = \"models_history/models_onnx\",\n    model_name: str = \"faster_rcnn_tuned\",\n) -&gt; None:\n    \"\"\"\n    Converting current model into ONNX format\n    :param model_name: converted model file name\n    :param export_path: destination directory for converted model\n\n    *required ONNX version: 1.16.1; pip install onnx=1.16.1\n    \"\"\"\n    model_to_export = self.model\n\n    # this operation requires switching the model into eval mode\n    model_to_export.eval()\n\n    # input template for ONNX converted network should be the same\n    input_tensor = torch.randn(\n        (4, 3, 800, 800), dtype=torch.float32, requires_grad=True\n    )\n    # input_tensor = input_tensor.to(self.device)\n\n    torch.onnx.export(\n        model_to_export,\n        (input_tensor,),\n        f\"{export_path}/{model_name}.onnx\",\n        export_params=True,\n        do_constant_folding=True,\n        opset_version=11,\n        input_names=[\"input\"],\n        output_names=[\"output\"],\n        dynamo=False,\n    )\n    self.logger.report_text(\"Model successfully exported into ONNX format\")\n</code></pre>"},{"location":"#core.experiment.Experiment.get_constants_from_config","title":"<code>get_constants_from_config()</code>","text":"<p>Parses given constants into tuple</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def get_constants_from_config(self) -&gt; tuple:\n    \"\"\"Parses given constants into tuple\"\"\"\n\n    model = self.config.get(\"model_name\", \"model\")\n    optim = self.config.get(\"optim_name\", \"\")\n    checkpoint_path = self.config.get(\n        \"checkpoint_path\", \"models_history/models_torch\"\n    )\n\n    num_epochs = self.config.get(\"num_epochs\", 5)\n\n    return model, optim, checkpoint_path, num_epochs\n</code></pre>"},{"location":"#core.experiment.Experiment.get_predictions_dataset","title":"<code>get_predictions_dataset(dataloader, threshold=0.5)</code>","text":"<p>Implements network performance evaluation process :param dataloader: PyTorch standard DataLoader which contains custom dataset :param threshold: filtering bound for predicted samples</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def get_predictions_dataset(\n    self, dataloader: DataLoader, threshold: float = 0.5\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Implements network performance evaluation process\n    :param dataloader: PyTorch standard DataLoader which contains custom dataset\n    :param threshold: filtering bound for predicted samples\n    \"\"\"\n    predictions = {\"image_id\": [], \"boxes\": [], \"IoU\": []}\n\n    # switching model into evaluation mode\n    self.model.to(self.device)\n    self.model.eval()\n\n    itr = 1\n\n    # evaluation loop\n    for images, targets, image_ids in dataloader:\n\n        images = list(image.to(self.device) for image in images)\n\n        # get predictions of the model\n        outputs = self.model(images)\n\n        for i, image in enumerate(images):\n\n            ground_truth = targets[i][\"boxes\"]\n            output_boxes = outputs[i][\"boxes\"].data.cpu().numpy()\n\n            scores = outputs[i][\"scores\"].data.cpu().numpy()\n\n            output_boxes = output_boxes[scores &gt;= threshold].astype(np.int32)\n\n            image_id = image_ids[i]\n\n            # Pillow class for drawing predicted bounding boxes\n            draw = ImageDraw.Draw(Image.open(f\"src/data/{image_id}.jpg\"))\n\n            # storing the iou's for each predicted object\n            pred_objects_iou = []\n\n            for box in output_boxes:\n\n                # iou computation for each predicted bbox\n                # torchvision.ops.box_iou returns Tensor after call\n                tensor_iou = box_iou(\n                    torch.tensor(ground_truth), torch.tensor(box.reshape(-1, 4))\n                )\n\n                # tensor conversion into python dtype\n                iou = round(float(torch.max(tensor_iou)), 4)\n\n                pred_objects_iou.append(iou)\n\n                predictions[\"image_id\"].append(image_id)\n                predictions[\"boxes\"].append(box)\n                predictions[\"IoU\"].append(iou)\n\n                draw.rectangle(xy=tuple(map(int, box)), outline=\"blue\", width=2)\n                draw.text(\n                    xy=(box[0], box[1]),\n                    text=f\"IoU: {iou}\",\n                    fill=\"black\",\n                    stroke=0.2,\n                )\n\n            # logging the image with predicted bounding boxes\n            self.logger.report_image(\n                title=\"image\",\n                series=f\"image sample: {image_id}\",\n                iteration=itr,\n                image=draw._image,\n            )\n\n            # scoring avg iou for image and logging it\n            self.logger.report_scalar(\n                title=\"avg IoU (Jaccard index)\",\n                series=f\"avg IoU\",\n                iteration=itr,\n                value=sum(pred_objects_iou)\n                / (len(output_boxes) if len(output_boxes) &gt; 0 else 1),\n            )\n\n            itr += 1\n\n    return pd.DataFrame.from_dict(predictions)\n</code></pre>"},{"location":"#core.experiment.Experiment.train","title":"<code>train(dataloader)</code>","text":"<p>Implements network training process :param dataloader: PyTorch standard DataLoader which contains custom dataset</p> Source code in <code>itmo_mlops_course\\core\\experiment.py</code> <pre><code>def train(self, dataloader: DataLoader) -&gt; None:\n    \"\"\"\n    Implements network training process\n    :param dataloader: PyTorch standard DataLoader which contains custom dataset\n    \"\"\"\n\n    # setting some counters and such things\n    itr = 1\n    start_time = time()\n    model_name, optim_name, checkpoint_path, num_epochs = (\n        self.get_constants_from_config()\n    )\n\n    # switching model into train mode\n    self.model.to(self.device)\n    self.model.train()\n\n    # losses history\n    loss_hist = Averager()\n\n    self.logger.report_text(\"Training process is started!\")\n\n    try:\n\n        # training loop\n        for epoch in range(num_epochs):\n\n            loss_hist.reset()\n\n            for images, targets, image_ids in dataloader:\n\n                images = list(image.to(self.device) for image in images)\n\n                targets = [\n                    {k: v.to(self.device) for k, v in t.items()} for t in targets\n                ]\n\n                # forward pass\n                loss_dict = self.model(images, targets)\n\n                # compute and send average batch loss\n                losses = sum(loss for loss in loss_dict.values())\n                loss_value = losses.item()\n\n                loss_hist.send(loss_value)\n\n                # backward pass\n                self.optimizer.zero_grad()\n                losses.backward()\n                self.optimizer.step()\n\n                # logging loss\n                self.logger.report_scalar(\n                    title=\"training loss\",\n                    series=\"avg batch loss\",\n                    iteration=itr,\n                    value=loss_hist.value,\n                )\n\n                # logging image samples from training set\n                [\n                    self.logger.report_image(\n                        title=\"image\",\n                        series=f\"Batch of images on itr: {itr}\",\n                        iteration=itr,\n                        image=Image.open(f\"src/data/{img}.jpg\"),\n                    )\n                    for img in image_ids\n                ]\n\n                self.logger.report_text(f\"Iteration: {itr}\")\n                itr += 1\n\n            # logging learning rate\n            self.logger.report_scalar(\n                title=\"learning rate\",\n                series=\"lr\",\n                iteration=itr,\n                value=self.lr_scheduler.get_last_lr()[0],\n            )\n\n            # learning rate update after each train epoch\n            self.lr_scheduler.step()\n\n            self.logger.report_text(f\"Train Epoch: {epoch}, Iteration: {itr}\")\n\n    # checkpoint for unplanned or manual training interruption\n    except Union[KeyboardInterrupt, TypeError, Exception]:\n\n        torch.save(\n            self.model.state_dict(), f=f\"{checkpoint_path}/{model_name}_{itr}.pth\"\n        )\n\n        self.logger.report_text(\n            \"Process are finished manually! Model saved into checkpoint\"\n        )\n\n    # model saving after successfully train\n    torch.save(\n        self.model.state_dict(),\n        f=f\"{checkpoint_path}/{model_name}_{optim_name}_tuned.pth\",\n    )\n\n    # logging training time\n    end_time = time()\n    self.logger.report_text(\n        f\"Execution time: {(end_time - start_time) / 60} minutes\"\n    )\n</code></pre>"},{"location":"#corepreprocessing","title":"<code>core.preprocessing</code>","text":""},{"location":"#core.preprocessing.get_processed_annotations","title":"<code>get_processed_annotations(images_set, xml_path)</code>","text":"<p>Creates a pandas dataframe for given image set and matchable markup :param images_set: path to the txt-file with image indexes :param xml_path: path to the current directory that contains xml-markup</p> Source code in <code>itmo_mlops_course\\core\\preprocessing.py</code> <pre><code>def get_processed_annotations(images_set: str, xml_path: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Creates a pandas dataframe for given image set and matchable markup\n    :param images_set: path to the txt-file with image indexes\n    :param xml_path: path to the current directory that contains xml-markup\n    \"\"\"\n    with open(file=images_set, mode=\"r\") as file:\n        f = file.read().split(\"\\n\")\n\n        return pd.concat(\n            [\n                parse_xml_anns(path=f\"{xml_path}/{img_id}.xml\", img_id=img_id)\n                for img_id in f\n            ],\n            ignore_index=True,\n        )\n</code></pre>"},{"location":"#core.preprocessing.parse_xml_anns","title":"<code>parse_xml_anns(path, img_id)</code>","text":"<p>Function that extracts and transforms annotations from given XML files with detection markup (bboxes) :param path: path to the current directory that contains xml-markup :param img_id: sample index to match markup file</p> Source code in <code>itmo_mlops_course\\core\\preprocessing.py</code> <pre><code>def parse_xml_anns(path: str, img_id: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Function that extracts and transforms annotations from\n    given XML files with detection markup (bboxes)\n    :param path: path to the current directory that contains xml-markup\n    :param img_id: sample index to match markup file\n    \"\"\"\n\n    anns = {\n        \"image_id\": [],\n        \"boxes\": [],\n        \"labels\": [],\n        \"xmin\": [],\n        \"ymin\": [],\n        \"xmax\": [],\n        \"ymax\": [],\n    }\n\n    tree = ET.parse(path)\n    root = tree.getroot()\n\n    objects = root.findall(\"object\")\n\n    for o in objects:\n        label = o.find(\"name\").text\n        bbox = o.find(\"bndbox\")\n\n        xmin = int(bbox.find(\"xmin\").text)\n        ymin = int(bbox.find(\"ymin\").text)\n        xmax = int(bbox.find(\"xmax\").text)\n        ymax = int(bbox.find(\"ymax\").text)\n\n        anns[\"image_id\"].append(int(img_id))\n        anns[\"labels\"].append(label)\n        anns[\"boxes\"].append([xmin, ymin, xmax, ymax])\n\n        anns[\"xmin\"].append(xmin)\n        anns[\"ymin\"].append(ymin)\n        anns[\"xmax\"].append(xmax)\n        anns[\"ymax\"].append(ymax)\n\n    return pd.DataFrame.from_dict(anns)\n</code></pre>"},{"location":"#utilsutils","title":"<code>utils.utils</code>","text":""},{"location":"#utils.utils.Averager","title":"<code>Averager</code>","text":"<p>loss averager</p> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>class Averager:\n    \"\"\"\n    loss averager\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the running statistics calculator.\n\n            Args:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        \"\"\"\n        Adds a value to the current total and increments the iteration count.\n\n          Args:\n            value: The amount to add to the running total.\n\n          Returns:\n            None\n        \"\"\"\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        \"\"\"\n        Returns the average value calculated so far.\n\n            Args:\n                None\n\n            Returns:\n                float: The average of the current total divided by the number of iterations.\n                       Returns 0 if no iterations have been performed yet.\n        \"\"\"\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total / self.iterations\n\n    def reset(self):\n        \"\"\"\n        Resets the running total and iteration count to zero.\n\n          Args:\n            None\n\n          Returns:\n            None\n        \"\"\"\n        self.current_total = 0.0\n        self.iterations = 0.0\n</code></pre>"},{"location":"#utils.utils.Averager.value","title":"<code>value</code>  <code>property</code>","text":"<p>Returns the average value calculated so far.</p> <pre><code>Args:\n    None\n\nReturns:\n    float: The average of the current total divided by the number of iterations.\n           Returns 0 if no iterations have been performed yet.\n</code></pre>"},{"location":"#utils.utils.Averager.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the running statistics calculator.</p> <pre><code>Args:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the running statistics calculator.\n\n        Args:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    self.current_total = 0.0\n    self.iterations = 0.0\n</code></pre>"},{"location":"#utils.utils.Averager.reset","title":"<code>reset()</code>","text":"<p>Resets the running total and iteration count to zero.</p> <p>Args:     None</p> <p>Returns:     None</p> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def reset(self):\n    \"\"\"\n    Resets the running total and iteration count to zero.\n\n      Args:\n        None\n\n      Returns:\n        None\n    \"\"\"\n    self.current_total = 0.0\n    self.iterations = 0.0\n</code></pre>"},{"location":"#utils.utils.Averager.send","title":"<code>send(value)</code>","text":"<p>Adds a value to the current total and increments the iteration count.</p> <p>Args:     value: The amount to add to the running total.</p> <p>Returns:     None</p> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def send(self, value):\n    \"\"\"\n    Adds a value to the current total and increments the iteration count.\n\n      Args:\n        value: The amount to add to the running total.\n\n      Returns:\n        None\n    \"\"\"\n    self.current_total += value\n    self.iterations += 1\n</code></pre>"},{"location":"#utils.utils.collate_fn","title":"<code>collate_fn(batch)</code>","text":"<p>Collates a batch of samples into a tuple of tensors.</p> <pre><code>Args:\n    batch: A list of samples, where each sample is a sequence.\n\nReturns:\n    tuple: A tuple containing the zipped elements from all sequences in the batch.\n           Each element of the tuple represents a different feature/dimension\n           across all samples in the batch.\n</code></pre> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def collate_fn(batch) -&gt; tuple:\n    \"\"\"\n    Collates a batch of samples into a tuple of tensors.\n\n        Args:\n            batch: A list of samples, where each sample is a sequence.\n\n        Returns:\n            tuple: A tuple containing the zipped elements from all sequences in the batch.\n                   Each element of the tuple represents a different feature/dimension\n                   across all samples in the batch.\n    \"\"\"\n    return tuple(zip(*batch))\n</code></pre>"},{"location":"#utils.utils.draw_image_boxes","title":"<code>draw_image_boxes(predicted, ground_truth=None, bbox_width=2, config=None)</code>","text":"<p>Function which draw image and its bboxes by PIL. You could specify bbox line width, text and line colour :param config: :param bbox_width: :param ground_truth: :param predicted:</p> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def draw_image_boxes(\n    predicted: pd.DataFrame,\n    ground_truth: pd.DataFrame = None,\n    bbox_width: int = 2,\n    config: dict = None,\n) -&gt; None:\n    \"\"\"\n    Function which draw image and its bboxes by PIL.\n    You could specify bbox line width, text and line colour\n    :param config:\n    :param bbox_width:\n    :param ground_truth:\n    :param predicted:\n    \"\"\"\n    default_label = \"aircraft\"\n\n    if not config:\n        config = {\n            # \"pred_obj_title\": \"\",\n            # \"pred_text_color\": \"\",\n            # \"pred_box_color\": \"\",\n            \"metric_name\": \"IoU\",\n            # \"gt_obj_title\": \"\",\n            # \"gt_text_color\": \"\",\n            # \"gt_box_color\": \"\",\n        }\n\n    image_ids = predicted[\"image_id\"].unique()\n\n    for img_id in image_ids:\n\n        draw = ImageDraw.Draw(Image.open(f\"src/data/{img_id}.jpg\"))\n\n        predictions_for_img = predicted[predicted[\"image_id\"] == img_id]\n\n        for index, row in predictions_for_img.iterrows():\n            ann_pred = tuple(map(int, row[\"boxes\"]))\n\n            draw.rectangle(\n                xy=ann_pred,\n                outline=config.get(\"pred_box_color\", \"blue\"),\n                width=bbox_width,\n            )\n\n            draw.text(\n                xy=(ann_pred[0], ann_pred[1]),\n                text=config.get(\"pred_obj_title\", default_label),\n                fill=config.get(\"pred_text_color\", \"black\"),\n                stroke_width=0.2,\n            )\n\n            metric = config.get(\"metric_name\", \"IoU\")\n            draw.text(\n                xy=(ann_pred[0], ann_pred[3]),\n                text=f\"{metric}: -&gt; {row[metric] if metric else 'no data'}\",\n                fill=config.get(\"metric_color\", \"black\"),\n                stroke_width=0.2,\n            )\n\n        if ground_truth is not None:\n\n            ground_truth_for_img = ground_truth[ground_truth[\"image_id\"] == img_id]\n\n            for index, row in ground_truth_for_img.iterrows():\n\n                ann_gt = tuple(map(int, row[\"boxes\"]))\n\n                draw.rectangle(\n                    xy=ann_gt,\n                    outline=config.get(\"gt_box_color\", \"red\"),\n                    width=bbox_width,\n                )\n\n                draw.text(\n                    xy=(ann_gt[0], ann_gt[1]),\n                    text=config.get(\"gt_obj_title\", default_label),\n                    fill=config.get(\"gt_text_color\", \"red\"),\n                    stroke_width=0.2,\n                )\n\n        draw._image.show()\n        time.sleep(2)\n</code></pre>"},{"location":"#utils.utils.get_image_paths","title":"<code>get_image_paths(indexes_file)</code>","text":"<p>Extracts paths for given images indexes</p> Source code in <code>itmo_mlops_course\\utils\\utils.py</code> <pre><code>def get_image_paths(indexes_file: str) -&gt; list[str]:\n    \"\"\"\n    Extracts paths for given images indexes\n    \"\"\"\n    with open(file=indexes_file, mode=\"r\") as f:\n        return [f\"src/data/{ind}.jpg\" for ind in f.read().split(\"\\n\")]\n</code></pre>"}]}